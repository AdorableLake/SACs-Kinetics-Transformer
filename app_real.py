## application.py
import streamlit as st
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import math
import matplotlib.pyplot as plt
import os
import data_encoder 

# ==========================================
# 1. é…ç½®è·¯å¾„
# ==========================================
MODEL_PATH = './training_logs_v3_6/model_v3.6_final_20251208_164608.pth' 
DATA_PATH = './processed_data/catalyst_dataset_v3_latest.pt'             

# ==========================================
# 2. æ™ºèƒ½è®¾å¤‡é€‰æ‹©é€»è¾‘
# ==========================================
def get_device():
    if torch.cuda.is_available():
        return torch.device("cuda")
    elif torch.backends.mps.is_available():
        return torch.device("mps")
    else:
        return torch.device("cpu")

# è·å–å½“å‰è®¾å¤‡
device = get_device()

# ==========================================
# 3. æ¨¡å‹ç»“æ„ (å¿…é¡»ä¸è®­ç»ƒä»£ç ä¸€è‡´)
# ==========================================
class PositionalEncoding(nn.Module):
    def __init__(self, d_model, max_len=5000):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe)

    def forward(self, x):
        return x + self.pe[:x.size(1), :]

class CatalystTransformer(nn.Module):
    def __init__(self, input_dim, output_dim=1, d_model=128, nhead=4, num_layers=3):
        super().__init__()
        self.feature_embedding = nn.Linear(input_dim, d_model)
        self.sequence_embedding = nn.Linear(output_dim, d_model)
        self.pos_encoder = PositionalEncoding(d_model)
        # æ¨ç†æ—¶ dropout è®¾ä¸º 0
        self.transformer = nn.Transformer(
            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,
            num_decoder_layers=num_layers, dim_feedforward=d_model*4,
            dropout=0.0, batch_first=True
        )
        self.output_head = nn.Linear(d_model, output_dim)

    def forward(self, src, tgt):
        src = self.feature_embedding(src).unsqueeze(1)
        tgt = self.sequence_embedding(tgt)
        tgt = self.pos_encoder(tgt)
        output = self.transformer(src, tgt)
        return self.output_head(output)

# ==========================================
# 4. èµ„æºåŠ è½½ (ä¿®å¤ç‰ˆï¼šFlatten + Safe Load)
# ==========================================
@st.cache_resource
def load_resources():
    if not os.path.exists(MODEL_PATH) or not os.path.exists(DATA_PATH):
        return None, None, None
    
    # 1. åŠ è½½æ•°æ®é›†åŒ… (è·å– Processor å’Œ Times)
    # ğŸ”¥ ä¿®å¤: weights_only=False è§£å†³å®‰å…¨æŠ¥é”™
    checkpoint = torch.load(DATA_PATH, map_location=device, weights_only=False)
    processor = checkpoint['processor']
    
    # 2. æ¢æµ‹è¾“å…¥ç»´åº¦
    dummy_input = {'Catalyst_Type': 'Fe-SAC', 'pH': 7}
    # ğŸ”¥ ä¿®å¤: .flatten() è§£å†³ç»´åº¦ä¸åŒ¹é…æŠ¥é”™
    input_dim = processor.process_single_row(dummy_input).flatten().shape[0]
    
    print(f"âœ… æ¨¡å‹è¾“å…¥ç‰¹å¾ç»´åº¦å·²æ ¡å‡†: {input_dim}")
    
    # 3. åˆå§‹åŒ–æ¨¡å‹å¹¶ç§»è‡³å¯¹åº”è®¾å¤‡
    model = CatalystTransformer(input_dim=input_dim).to(device)
    
    # 4. åŠ è½½æƒé‡
    # ğŸ”¥ ä¿®å¤: weights_only=False
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device, weights_only=False))
    model.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼
    
    return model, processor, checkpoint.get('times', np.arange(61))

# ğŸ”¥ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¿…é¡»åœ¨è¿™é‡Œæ‰§è¡Œå‡½æ•°ï¼Œç»™ model èµ‹å€¼ï¼ğŸ”¥ğŸ”¥
model, processor, target_times = load_resources()

# ==========================================
# 5. Streamlit ç•Œé¢
# ==========================================
st.set_page_config(page_title="SACs ç±»èŠ¬é¡¿åŠ¨åŠ›å­¦é¢„æµ‹ç³»ç»Ÿ", layout="wide")
st.title("ğŸ§ª (Real-AI) å•åŸå­å‚¬åŒ–å‰‚é©±åŠ¨çš„ç±»èŠ¬é¡¿ååº”åŠ¨åŠ›å­¦é¢„æµ‹ç³»ç»Ÿ V1")

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½æˆåŠŸ
if model is None:
    st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„è®¾ç½®ã€‚\n\nModel: {MODEL_PATH}\nData: {DATA_PATH}")
    st.stop()

# --- ä¾§è¾¹æ  ---
st.sidebar.header("1. ååº”æ¡ä»¶è®¾ç½®")

# åŠ¨æ€è·å–é€‰é¡¹
cat_options = processor.categories['Catalyst_Type']
poll_options = processor.categories['Pollutant']
ox_options = processor.categories['Oxidant']
anion_options = processor.categories['Anion_Type']

catalyst_type = st.sidebar.selectbox("å‚¬åŒ–å‰‚", cat_options, index=0)
pollutant = st.sidebar.selectbox("æ±¡æŸ“ç‰©", poll_options, index=0)
oxidant = st.sidebar.selectbox("æ°§åŒ–å‰‚", ox_options, index=0)
anion_type = st.sidebar.selectbox("å…±å­˜é˜´ç¦»å­", anion_options, index=0)

st.sidebar.header("2. æ•°å€¼å‚æ•°")
ph_val = st.sidebar.slider("pH å€¼", 1.0, 14.0, 7.0)
cat_conc = st.sidebar.number_input("å‚¬åŒ–å‰‚æµ“åº¦ (g/L)", 0.0, 5.0, 0.1)
poll_conc = st.sidebar.number_input("æ±¡æŸ“ç‰©æµ“åº¦ (mg/L)", 0.0, 100.0, 10.0)
pms_conc = st.sidebar.number_input("æ°§åŒ–å‰‚æµ“åº¦ (g/L)", 0.0, 10.0, 0.15)
anion_conc = st.sidebar.number_input("é˜´ç¦»å­æµ“åº¦ (mM)", 0.0, 100.0, 0.0)
temp_val = st.sidebar.number_input("æ¸©åº¦ (K)", 273.0, 373.0, 298.0)

st.sidebar.markdown("---")
# æ˜¾ç¤ºå½“å‰ç¡¬ä»¶çŠ¶æ€
st.sidebar.caption(f"âš¡ï¸ Computing Device: **{str(device).upper()}**")

run_btn = st.sidebar.button("ğŸš€ è¿è¡Œ Transformer æ¨ç†")

# --- ä¸»æ˜¾ç¤ºåŒº ---
col1, col2 = st.columns([1, 2])

with col1:
    st.info(f"âœ… æ¨¡å‹çŠ¶æ€: åœ¨çº¿ ({device})")
    input_dict = {
        'Catalyst': catalyst_type,
        'Pollutant': pollutant,
        'Oxidant': oxidant,
        'pH': ph_val,
        'T(K)': temp_val
    }
    st.write("å½“å‰è¾“å…¥æ‘˜è¦ï¼š")
    st.table(pd.DataFrame(input_dict, index=[0]).T)

with col2:
    if run_btn:
        try:
            # 1. æ„å»ºå®Œæ•´çš„è¾“å…¥å­—å…¸
            full_input = {
                'Catalyst_Type': catalyst_type,
                'Pollutant': pollutant,
                'Oxidant': oxidant,
                'Anion_Type': anion_type,
                'pH': ph_val,
                'Catalyst_Conc': cat_conc,
                'Oxidant_Conc': pms_conc,
                'Pollutant_Conc_mgL': poll_conc,
                'Anion_Conc_mM': anion_conc,
                'Temp_K': temp_val
            }
            
            # 2. é¢„å¤„ç† (CPU -> Tensor -> Device)
            # ğŸ”¥ ä¿®å¤: .flatten() ç¡®ä¿ç»´åº¦æ­£ç¡®
            feature_vec = processor.process_single_row(full_input).flatten()
            feature_tensor = torch.tensor(feature_vec, dtype=torch.float32).unsqueeze(0).to(device)
            
            # 3. å‡†å¤‡ Decoder è¾“å…¥
            seq_len = len(target_times)
            tgt_input = torch.full((1, seq_len, 1), 0.5).to(device)
            
            # 4. æ¨ç†
            with torch.no_grad():
                output = model(feature_tensor, tgt_input)
                pred_curve = output.cpu().numpy().flatten()
            
            # 5. åå¤„ç† (ç‰©ç†é”)
            pred_curve[0] = 1.0
            for i in range(1, len(pred_curve)):
                if pred_curve[i] > pred_curve[i-1]: 
                    pred_curve[i] = pred_curve[i-1]
            
            # 6. ç»˜å›¾
            st.success("é¢„æµ‹å®Œæˆï¼")
            
            fig, ax = plt.subplots(figsize=(8, 4))
            ax.plot(target_times, pred_curve, 'r-o', linewidth=2, label='AI Prediction')
            ax.set_xlabel("Time (min)")
            ax.set_ylabel("C/C0")
            ax.set_ylim(-0.05, 1.05)
            ax.set_title(f"{catalyst_type} degrading {pollutant}")
            ax.grid(True, linestyle='--', alpha=0.5)
            ax.legend()
            st.pyplot(fig)
            
            # 7. ä¸‹è½½æ•°æ®
            df_res = pd.DataFrame({"Time (min)": target_times, "Predicted C/C0": pred_curve})
            st.dataframe(df_res.T)
            
        except Exception as e:
            st.error(f"æ¨ç†é”™è¯¯: {e}")
            st.write(e) # æ‰“å°è¯¦ç»†é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è°ƒæ•´å‚æ•°ï¼Œç„¶åç‚¹å‡»è¿è¡Œ")